#!/usr/bin/env python3
"""
SCRIPT PRINCIPAL DE TESTS - RESERVAFLOW
======================================

Este script ejecuta todos los tipos de tests organizados:
- Tests unitarios
- Tests de integraciÃ³n  
- Tests realistas
- Tests de validaciÃ³n
"""

import os
import sys
import subprocess
import argparse
from datetime import datetime

def run_command(command, description, capture_output=False):
    """Ejecutar comando con manejo de errores"""
    print(f"\nğŸ”„ {description}")
    print(f"   Comando: {command}")
    print("-" * 60)
    
    try:
        if capture_output:
            result = subprocess.run(
                command, 
                shell=True, 
                capture_output=True, 
                text=True,
                cwd=os.path.dirname(os.path.abspath(__file__))
            )
            return result.returncode == 0, result.stdout, result.stderr
        else:
            result = subprocess.run(
                command, 
                shell=True,
                cwd=os.path.dirname(os.path.abspath(__file__))
            )
            return result.returncode == 0, "", ""
    except Exception as e:
        print(f"âŒ Error ejecutando comando: {e}")
        return False, "", str(e)

def run_unit_tests():
    """Ejecutar tests unitarios"""
    success, stdout, stderr = run_command(
        "python -m pytest tests/unit/ -v --tb=short",
        "Ejecutando Tests Unitarios"
    )
    return success

def run_integration_tests():
    """Ejecutar tests de integraciÃ³n"""
    success, stdout, stderr = run_command(
        "python -m pytest tests/integration/ -v --tb=short",
        "Ejecutando Tests de IntegraciÃ³n"
    )
    return success

def run_realistic_tests():
    """Ejecutar tests realistas"""
    success, stdout, stderr = run_command(
        "python -m pytest tests/realistic/ -v --tb=short",
        "Ejecutando Tests Realistas"
    )
    return success

def run_validation_tests():
    """Ejecutar tests de validaciÃ³n especÃ­ficos"""
    print("\nğŸ” Ejecutando Tests de ValidaciÃ³n EspecÃ­ficos")
    print("-" * 60)
    
    validation_tests = [
        ("tests/validation/test_double_booking.py", "Double Booking Prevention"),
        ("tests/validation/test_email_config.py", "Email Configuration"),
        ("tests/validation/test_full_reservation_flow.py", "Full Reservation Flow"),
        ("tests/validation/test_reminder_system.py", "Reminder System"),
        ("tests/validation/test_all_problems_fixed.py", "All Problems Fixed Validation"),
    ]
    
    all_passed = True
    for test_file, description in validation_tests:
        success, stdout, stderr = run_command(
            f"python {test_file}",
            f"ğŸ§ª {description}"
        )
        all_passed = all_passed and success
        if not success:
            print(f"   âŒ FallÃ³: {description}")
        else:
            print(f"   âœ… PasÃ³: {description}")
    
    return all_passed

def run_realistic_demonstrations():
    """Ejecutar demostraciones realistas"""
    print("\nğŸ­ Ejecutando Demostraciones Realistas")
    print("-" * 60)
    
    demonstrations = [
        ("tests/scripts/realistic_test_demonstration.py", "Realistic Test Demonstration"),
        ("tests/scripts/final_realistic_test_report.py", "Final Realistic Report"),
    ]
    
    all_passed = True
    for script_file, description in demonstrations:
        success, stdout, stderr = run_command(
            f"python {script_file}",
            f"ğŸ¯ {description}"
        )
        all_passed = all_passed and success
        if not success:
            print(f"   âŒ FallÃ³: {description}")
        else:
            print(f"   âœ… PasÃ³: {description}")
    
    return all_passed

def generate_test_report(results):
    """Generar reporte final de todos los tests"""
    print("\n" + "="*80)
    print("ğŸ“Š REPORTE FINAL DE TESTS - RESERVAFLOW")
    print("="*80)
    
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"ğŸ• Ejecutado: {timestamp}")
    
    total_categories = len(results)
    passed_categories = sum(1 for success in results.values() if success)
    success_rate = (passed_categories / total_categories) * 100 if total_categories > 0 else 0
    
    print("\nğŸ“ˆ RESUMEN EJECUTIVO:")
    print(f"   Total de categorÃ­as: {total_categories}")
    print(f"   CategorÃ­as exitosas: {passed_categories}")
    print(f"   Tasa de Ã©xito: {success_rate:.1f}%")
    
    print("\nğŸ“‹ DETALLE POR CATEGORÃA:")
    
    category_names = {
        'unit': 'Tests Unitarios',
        'integration': 'Tests de IntegraciÃ³n', 
        'realistic': 'Tests Realistas',
        'validation': 'Tests de ValidaciÃ³n',
        'demonstrations': 'Demostraciones Realistas'
    }
    
    for category, success in results.items():
        name = category_names.get(category, category)
        status = "âœ… PASÃ“" if success else "âŒ FALLÃ“"
        print(f"   {name:25} {status}")
    
    print("\nğŸ’¡ ESTRUCTURA DE TESTS ORGANIZADA:")
    print("   ğŸ“ tests/unit/           - Tests unitarios de modelos, vistas, tareas")
    print("   ğŸ“ tests/integration/    - Tests de integraciÃ³n API y flujos") 
    print("   ğŸ“ tests/realistic/      - Tests con servicios reales (Redis, BD)")
    print("   ğŸ“ tests/validation/     - Tests de validaciÃ³n especÃ­ficos")
    print("   ğŸ“ tests/scripts/        - Scripts de demostraciÃ³n y herramientas")
    print("   ğŸ“ tests/fixtures/       - Factories y fixtures compartidos")
    print("   ğŸ“ docs/                 - DocumentaciÃ³n tÃ©cnica")
    
    if success_rate >= 80:
        print("\nğŸ† CONCLUSIÃ“N:")
        print("   âœ… SISTEMA DE TESTS ROBUSTO Y ORGANIZADO")
        print("   ğŸ“š Todos los tipos de tests estÃ¡n funcionando correctamente")
        print("   ğŸš€ ReservaFlow tiene cobertura completa de testing")
    elif success_rate >= 60:
        print("\nâš ï¸ CONCLUSIÃ“N:")
        print("   ğŸ”§ SISTEMA DE TESTS MAYORMENTE FUNCIONAL")
        print("   ğŸ“ Algunas categorÃ­as necesitan ajustes menores")
    else:
        print("\nâŒ CONCLUSIÃ“N:")
        print("   ğŸš¨ SISTEMA DE TESTS REQUIERE ATENCIÃ“N")
        print("   ğŸ”§ Problemas crÃ­ticos en mÃºltiples categorÃ­as")
    
    return success_rate >= 80

def main():
    """FunciÃ³n principal"""
    parser = argparse.ArgumentParser(description='Ejecutar tests de ReservaFlow')
    parser.add_argument('--type', choices=['unit', 'integration', 'realistic', 'validation', 'demonstrations', 'all'], 
                       default='all', help='Tipo de tests a ejecutar')
    parser.add_argument('--quick', action='store_true', help='Ejecutar solo tests rÃ¡pidos')
    
    args = parser.parse_args()
    
    print("ğŸ§ª SISTEMA DE TESTS ORGANIZADO - RESERVAFLOW")
    print("="*80)
    print("ğŸ¯ Ejecutando tests organizados por categorÃ­as")
    print("ğŸ“Š Estructura optimizada para desarrollo y CI/CD")
    
    results = {}
    
    if args.type in ['unit', 'all']:
        results['unit'] = run_unit_tests()
    
    if args.type in ['integration', 'all'] and not args.quick:
        results['integration'] = run_integration_tests()
    
    if args.type in ['realistic', 'all'] and not args.quick:
        results['realistic'] = run_realistic_tests()
    
    if args.type in ['validation', 'all'] and not args.quick:
        results['validation'] = run_validation_tests()
    
    if args.type in ['demonstrations', 'all'] and not args.quick:
        results['demonstrations'] = run_realistic_demonstrations()
    
    # Generar reporte final
    overall_success = generate_test_report(results)
    
    print("\nğŸ‰ EJECUCIÃ“N COMPLETADA!")
    if overall_success:
        print("   âœ… Todos los tests estÃ¡n organizados y funcionando")
        sys.exit(0)
    else:
        print("   âš ï¸ Algunas categorÃ­as de tests necesitan atenciÃ³n")
        sys.exit(1)

if __name__ == "__main__":
    main()